1.Prompt Enginnering是对大语言模型的终端应用非常有效的使用手段。请简述其实现形式，并从语言模型的原理尝试解释为什么其有效。
2.假设你想要使用Python，开发一个框架用于帮助用户调试不同场景下使用的Prompt模板，举几个简单的例子包括:不同语言的翻译任务，情感极性分类判别等。请简要分析应该怎样做框架的系统设计及类抽象，并给出简要的逻辑流程示例(不用给具体代码)

Prompt Engineering 是一种有效利用大语言模型的方法. 具体而言, 对于某一特定的任务, 预先设计好 Prompt, 然后讲所需的文本编码到prompt中, 作为LLM的输入, 然后调用大模型生成输出, 最后经过后处理和解释得到最终任务的结果. 
其有效的原因, 在于LM在训练的过程中, 学习了训练语料中的语言规律, 以及语义信息. 而我们通过prompt作为诱导, 可以让模型的生成结果更加符合我们的预期.


1.基于Query的单次语义检索的检索模块可能会碰到什么问题?
2.在有大语言模型参与的情况下，你可以怎样重新设计检索模块?

直接基于query来进行语义检索, 会存在query内容和召回结果之间的不匹配的问题. 这是因为query的内容和我们期望的关联段落之间不是简单的语义相似, 而存在着较为复杂的因果关联. 因此不能直接用语义相似检索. 
在有LLM的情况下, 可以让LLM来进行query文本的改写, 例如, 将query中存在的语义实体进行抽取, 并重新组织成合适的查询文本, 再放到检索模块中进行检索. 
