
两道判断, 两道选择, 三道简答. 

Q: 1] 解释表示学习? 2] 从先验概率分布和决策边界的角度来理解表示学习? 3] 为什么现在表示学习都用深度学习?
1. 表示学习指的是, 通过有监督或者无监督学习的方式, 来得到数据的特征 (空间). 
相较于人工设计特征 (得到物品表示并完成下游任务), 通过表示学习可以自动地学习到大量数据中的特征信号, 减少了人工设计特征的成本和偏好误差. 
1. 从先验概率分布的角度来理解, 表示学习的目标在于学习样本空间上的分布特征, 并用更加稠密高效的方式来对于样本分布进行描述. 
从有监督的决策边界的角度来理解, 表示学习在学习过程中, 通过对于特征空间的学习, 得到有监督样本上表现更好的决策边界 (这一过程中优化了特征空间). 
1.  表示学习的目标在于得到样本表示向量, 而深度学习能够自然地将样本的表示作为优化目标 (通过embedding层) , 并且能够简单地通过梯度下降的优化算法来学习样本表示. 
同时, 深度学习对于不同种类的回归或分类任务有着统一的形式, 并且有着强大的表达能力, 取得更好的学习效果, 也即能够优化得到更好的表示空间. 


Q: 1] 解释一下Prompt Engineering? 2] 对于用户进行prompt测试的场景, 应该怎样来设计调用的框架和类抽象? 
1. Prompt Engineering 即设计好给LLM的输入的内容, 通过和语言模型进行文本输入-文本输出的方式的交互, 来完成所需要的各种任务. 
其有效的来源在于, LLM在预训练和微调的过程中, 记忆学习了类似prompt的输入的输出, 从而对于当前的prompt, 通过学习到的概率分布来得到较为符合要求的结果. 具体而言, 语言模型作为概率模型建模了 P(x_i | x_{0:i-1}) 的分布, 从而能够基于此前的信息来对于之后更有可能承接的那些文字进行预测输出. 
2. 任务目标为对于prompt调试提供一套框架, 为此需要做到: 
    1) 设计prompt的语法和形式, 例如, 需要在prompt中给需要翻译的输入文字留好位置, 并且给prompt预留好前缀、后缀等可供用户自定义的部分. (参考LangChain中的设计)
    2) 提供统一便捷的和LLM交互的API, 例如支持ChatGPT和Claude的统一的调用接口. 并且对于大批量访问需要做好调度策略. 
    3) 为协助完成测试任务, 需要设计包装测试样例的数据类, 以完成流程化的数据载入和评测流程. 
总结来说, 可以实现 Prompt, LLM, Scheduler, Data, Tester 等类抽象. 
在用户侧, 其通过简单的方式来完成整体的测试调用, 只需要修改Prompt部分的设计即可. 


Q: 1] 语义检索的问题? 2] LLM在语义检索中的应用? 重新设计检索系统. 
1. 这里的语义检索 (区别于基于关键词或BM25等检索方式) 理解为, 通过向量库的方式来完成语料库中的文本索引, 将它们映射到同一个语义空间中. 对于所需要的query文本, 将其采用相同的Encoder来得到查询向量, 在向量库中通过最近邻搜索得到语义上相近的文本. 它可能的问题在于, 
    1) 查询文本可能是模糊的, 只是提供了模糊的意图, 乃至某些信息是缺失的. 例如「近期有什么院线电影」中近期的时间概念需要明确; 
    2) 查询和相关文本之间是不对称的关系, 单纯靠相同的Encoder来计算语义相似性存在一定的误差. 
2. 在检索模块的设计上, LLM可以有如下的应用: 
    1) 增强上面提到的语义检索模块, 利用LLM对于查询文本进行信息的补充和文字上的改写, 从而得到更好的检索query. 
    2) 结合基于关键字的检索方案, 例如, 对于模糊的查询, 先让大模型来生成该描述可能对应到的关键词, 再基于关键词从库中进行检索. (参考 ChatLaw中的 keywordLLM 模型)

